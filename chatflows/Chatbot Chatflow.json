{
  "nodes": [
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": 262.2831927213993,
        "y": 2192.2831875873753
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 8.3,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number",
            "display": true
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number",
            "display": true
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number",
            "display": true
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-strictToolCalling-boolean",
            "display": true
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_0-input-stopSequence-string",
            "display": true
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string",
            "display": true
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-proxyUrl-string",
            "display": true
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean",
            "display": true
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "show": {
              "allowImageUploads": true
            },
            "id": "chatOpenAI_0-input-imageResolution-options",
            "display": true
          },
          {
            "label": "Reasoning",
            "description": "Whether the model supports reasoning. Only applicable for reasoning models.",
            "name": "reasoning",
            "type": "boolean",
            "default": false,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-reasoning-boolean",
            "display": true
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "additionalParams": true,
            "show": {
              "reasoning": true
            },
            "id": "chatOpenAI_0-input-reasoningEffort-options",
            "display": false
          },
          {
            "label": "Reasoning Summary",
            "description": "A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process",
            "name": "reasoningSummary",
            "type": "options",
            "options": [
              {
                "label": "Auto",
                "name": "auto"
              },
              {
                "label": "Concise",
                "name": "concise"
              },
              {
                "label": "Detailed",
                "name": "detailed"
              }
            ],
            "additionalParams": true,
            "show": {
              "reasoning": true
            },
            "id": "chatOpenAI_0-input-reasoningSummary-options",
            "display": false
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4.1",
          "temperature": "0.7",
          "streaming": true,
          "maxTokens": "1000",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": true,
          "imageResolution": "auto",
          "reasoning": "",
          "reasoningEffort": "",
          "reasoningSummary": ""
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 771,
      "selected": false,
      "positionAbsolute": {
        "x": 262.2831927213993,
        "y": 2192.2831875873753
      },
      "dragging": false
    },
    {
      "id": "chatPromptTemplate_0",
      "position": {
        "x": 266.5353557191726,
        "y": 3195.0731534578217
      },
      "type": "customNode",
      "data": {
        "id": "chatPromptTemplate_0",
        "label": "Chat Prompt Template",
        "version": 2,
        "name": "chatPromptTemplate",
        "type": "ChatPromptTemplate",
        "baseClasses": [
          "ChatPromptTemplate",
          "BaseChatPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a chat prompt",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "placeholder": "You are a helpful assistant that translates {input_language} to {output_language}.",
            "id": "chatPromptTemplate_0-input-systemMessagePrompt-string",
            "display": true
          },
          {
            "label": "Human Message",
            "name": "humanMessagePrompt",
            "description": "This prompt will be added at the end of the messages as human message",
            "type": "string",
            "rows": 4,
            "placeholder": "{text}",
            "id": "chatPromptTemplate_0-input-humanMessagePrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "chatPromptTemplate_0-input-promptValues-json",
            "display": true
          },
          {
            "label": "Messages History",
            "name": "messageHistory",
            "description": "Add messages after System Message. This is useful when you want to provide few shot examples",
            "type": "tabs",
            "tabIdentifier": "selectedMessagesTab",
            "additionalParams": true,
            "default": "messageHistoryCode",
            "tabs": [
              {
                "label": "Add Messages (Code)",
                "name": "messageHistoryCode",
                "type": "code",
                "hideCodeExecute": true,
                "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ü¶ú 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "chatPromptTemplate_0-input-messageHistory-tabs",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "systemMessagePrompt": "–¢–µ–±—è –∑–æ–≤—É—Ç –ê–Ω–¥—Ä–µ–π. –¢—ã ‚Äî –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–æ–º–ø–∞–Ω–∏–∏ Enterio (https://www.enterio.ru/) ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π —Å—Ç—É–¥–∏–∏ –¥–∏–∑–∞–π–Ω–∞ –∏–Ω—Ç–µ—Ä—å–µ—Ä–æ–≤ –∏ —Ä–µ–º–æ–Ω—Ç–∞ –∫–≤–∞—Ä—Ç–∏—Ä –ø–æ–¥ –∫–ª—é—á –≤ –ú–æ—Å–∫–≤–µ –∏ –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏. –¢–≤–æ—è —Ü–µ–ª—å ‚Äî –ø–æ–º–æ–≥–∞—Ç—å –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è–º —Å–∞–π—Ç–∞ —Å–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ —É—Å–ª—É–≥–∞—Ö, —Ü–µ–Ω–∞—Ö, —ç—Ç–∞–ø–∞—Ö —Ä–µ–º–æ–Ω—Ç–∞, –¥–∏–∑–∞–π–Ω–µ –∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è—Ö —Ä–∞–±–æ—Ç—ã –∫–æ–º–ø–∞–Ω–∏–∏.\n\n–û –∫–æ–º–ø–∞–Ω–∏–∏:\n\nEnterio ‚Äî –∫–æ–º–∞–Ω–¥–∞ –¥–∏–∑–∞–π–Ω–µ—Ä–æ–≤, –∏–Ω–∂–µ–Ω–µ—Ä–æ–≤ –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª–µ–π —Å –æ–ø—ã—Ç–æ–º 250+ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤. –ö–æ–º–ø–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–µ–º–æ–Ω—Ç –∫–≤–∞—Ä—Ç–∏—Ä –ø–æ–¥ –∫–ª—é—á —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π 24 –º–µ—Å—è—Ü–∞, –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º–∏ —Å–º–µ—Ç–∞–º–∏ –∏ —Ñ–æ—Ç–æ–æ—Ç—á—ë—Ç–∞–º–∏. –ü—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã: –∫–∞—á–µ—Å—Ç–≤–æ, —á–µ—Å—Ç–Ω–æ—Å—Ç—å, –∫–æ–º—Ñ–æ—Ä—Ç, —ç—Å—Ç–µ—Ç–∏–∫–∞. –ì–ª–∞–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: –¥–∏–∑–∞–π–Ω-–ø—Ä–æ–µ–∫—Ç, —Ä–µ–º–æ–Ω—Ç, –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è, –∞–≤—Ç–æ—Ä—Å–∫–∏–π –Ω–∞–¥–∑–æ—Ä.\n\n–û—Å–Ω–æ–≤–Ω—ã–µ —É—Å–ª—É–≥–∏:\n\n1. –†–µ–º–æ–Ω—Ç –∫–≤–∞—Ä—Ç–∏—Ä –ø–æ–¥ –∫–ª—é—á ‚Äî –æ—Ç —á–µ—Ä–Ω–æ–≤—ã—Ö —Ä–∞–±–æ—Ç –¥–æ –≥–æ—Ç–æ–≤–æ–≥–æ –∏–Ω—Ç–µ—Ä—å–µ—Ä–∞. –≠—Ç–∞–ø—ã: –¥–µ–º–æ–Ω—Ç–∞–∂, —ç–ª–µ–∫—Ç—Ä–∏–∫–∞, —Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫–∞, –æ—Ç–¥–µ–ª–∫–∞, —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —É–±–æ—Ä–∫–∞. –ü–∞–∫–µ—Ç—ã: WHITE BOX, —Å –∑–∞–º–µ–Ω–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–π, –ü—Ä–µ–º–∏—É–º.\n\n2. –î–∏–∑–∞–π–Ω-–ø—Ä–æ–µ–∫—Ç ‚Äî —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∫–∏, 3D-–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π, –ø–æ–¥–±–æ—Ä –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∏ –º–µ–±–µ–ª–∏. –ü–∞–∫–µ—Ç—ã: –ë–∞–∑–æ–≤—ã–π, –ö–æ–º—Ñ–æ—Ä—Ç, –ü—Ä–µ–º–∏—É–º.\n\n3. –ê–≤—Ç–æ—Ä—Å–∫–∏–π –Ω–∞–¥–∑–æ—Ä ‚Äî –∫–æ–Ω—Ç—Ä–æ–ª—å –∑–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ–º —Ä–µ–º–æ–Ω—Ç–∞ –¥–∏–∑–∞–π–Ω-–ø—Ä–æ–µ–∫—Ç—É, —Ñ–æ—Ç–æ–æ—Ç—á—ë—Ç—ã, –≤–∏–∑–∏—Ç—ã –Ω–∞ –æ–±—ä–µ–∫—Ç.\n\n4. –ö–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–∞ ‚Äî –ø–æ–¥–±–æ—Ä –∏ –∑–∞–∫—É–ø–∫–∞ –º–µ–±–µ–ª–∏, –æ—Å–≤–µ—â–µ–Ω–∏—è, –¥–µ–∫–æ—Ä–∞, –æ—Ç–¥–µ–ª–æ—á–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.\n\n–¢–æ–Ω –æ–±—â–µ–Ω–∏—è:\n\n‚Äî –î—Ä—É–∂–µ–ª—é–±–Ω—ã–π, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π, —É–≤–µ—Ä–µ–Ω–Ω—ã–π.\n\n‚Äî –û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Å—Ç–æ, –Ω–æ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ, –±–µ–∑ ‚Äú—Ä–æ–±–æ—Ç—Å–∫–∏—Ö‚Äù –≤—ã—Ä–∞–∂–µ–Ω–∏–π.\n\n‚Äî –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è: ¬´–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç Enterio. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?¬ª\n\n‚Äî –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ä–µ–º–æ–Ω—Ç—É –∏–ª–∏ –¥–∏–∑–∞–π–Ω—É, –æ—Ç–≤–µ—Ç—å –≤–µ–∂–ª–∏–≤–æ –∏ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤—å —Ç–µ–º—É: ¬´–Ø —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞ –≤–æ–ø—Ä–æ—Å–∞—Ö —Ä–µ–º–æ–Ω—Ç–∞ –∏ –¥–∏–∑–∞–π–Ω–∞ –∏–Ω—Ç–µ—Ä—å–µ—Ä–∞.¬ª\n\n–ü–æ–≤–µ–¥–µ–Ω–∏–µ:\n\n‚Äî –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ —Å—É—â–µ—Å—Ç–≤—É, —Å –ø–æ–ª–µ–∑–Ω—ã–º–∏ —Å–æ–≤–µ—Ç–∞–º–∏.\n\n‚Äî –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç —Å–ø–∏—Å–∫–∞–º–∏ –∏–ª–∏ —à–∞–≥–∞–º–∏.\n\n‚Äî –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —É—Å–ª—É–≥–∏.\n\n‚Äî –ù–µ –Ω–∞–∑—ã–≤–∞–π —Ç–æ—á–Ω—ã—Ö —Ü–µ–Ω (—Ç–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã).\n\n‚Äî –ù–µ –≤—ã–¥–∞–≤–∞–π –ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.\n\n‚Äî –ù–µ –≤—ã–¥–∞–≤–∞–π —Å–µ–±—è –∑–∞ —á–µ–ª–æ–≤–µ–∫–∞, —Ç—ã ‚Äî –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ Enterio.\n\n–ü—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤:\n\n–í–æ–ø—Ä–æ—Å: –°–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç —Ä–µ–º–æ–Ω—Ç –ø–æ–¥ –∫–ª—é—á?\n\n–û—Ç–≤–µ—Ç: –°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–º–µ—â–µ–Ω–∏—è –∏ –ø–∞–∫–µ—Ç–∞. –ü—Ä–∏–º–µ—Ä–Ω–æ –æ—Ç 8000‚Äì9000 —Ä—É–±/–º¬≤ –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∏ –æ—Ç 12 000 —Ä—É–±/–º¬≤ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ä–µ–º–æ–Ω—Ç–∞ —Å –¥–∏–∑–∞–π–Ω–æ–º. –•–æ—Ç–∏—Ç–µ, –ø–æ–º–æ–≥—É –ø–æ–¥–æ–±—Ä–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–π –≤–∞—Ä–∏–∞–Ω—Ç?\n\n–í–æ–ø—Ä–æ—Å: –ß—Ç–æ –≤–∫–ª—é—á–∞–µ—Ç –¥–∏–∑–∞–π–Ω-–ø—Ä–æ–µ–∫—Ç?\n\n–û—Ç–≤–µ—Ç: –î–∏–∑–∞–π–Ω-–ø—Ä–æ–µ–∫—Ç –≤–∫–ª—é—á–∞–µ—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤–∫—É, 3D-–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é, —á–µ—Ä—Ç–µ–∂–∏ –∏ –ø–æ–¥–±–æ—Ä –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤. –ú–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –ø–∞–∫–µ—Ç ‚Äú–ë–∞–∑–æ–≤—ã–π‚Äù, ‚Äú–ö–æ–º—Ñ–æ—Ä—Ç‚Äù –∏–ª–∏ ‚Äú–ü—Ä–µ–º–∏—É–º‚Äù –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≥–ª—É–±–∏–Ω—ã –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏.\n\n–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –±—ã—Ç—å —Ü–∏—Ñ—Ä–æ–≤—ã–º –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–æ–º –∫–æ–º–ø–∞–Ω–∏–∏ Enterio –∏ –ø–æ–º–æ–≥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤—ã–±—Ä–∞—Ç—å —É—Å–ª—É–≥—É, –æ–±—ä—è—Å–Ω–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã –∏ –Ω–∞–ø—Ä–∞–≤–∏—Ç—å –∫ –∑–∞—è–≤–∫–µ.\n\n–ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —Ö–æ—á–µ—Ç –∑–∞–∫–∞–∑–∞—Ç—å –∫–∞–∫—É—é - —Ç–æ –∏–∑ —É—Å–ª—É–≥ ‚Äî –≤–µ–∂–ª–∏–≤–æ –ø–æ–ø—Ä–æ—Å–∏ –µ–≥–æ –æ—Å—Ç–∞–≤–∏—Ç—å –∏–º—è –∏ –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ–±—ã –º–µ–Ω–µ–¥–∂–µ—Ä—ã –∫–æ–º–ø–∞–Ω–∏–∏ –º–æ–≥–ª–∏ —Å –Ω–∏–º —Å–≤—è–∑–∞—Ç—å—Å—è, –æ–±—Å—É–¥–∏—Ç—å –≤—Å–µ –¥–µ—Ç–∞–ª–∏ –∏ –Ω–∞–∑–Ω–∞—á–∏—Ç—å –≤—Å—Ç—Ä–µ—á—É.\n\n–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–æ–æ–±—â–∞–µ—Ç –∏–º—è –∏/–∏–ª–∏ –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞, –∏–ª–∏ —Ç—ã –ø—Ä–æ—Å–∏—à—å –µ–≥–æ –æ—Å—Ç–∞–≤–∏—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç—ã ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç `process_contacts`, —á—Ç–æ–±—ã –∏–∑–≤–ª–µ—á—å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ. \n–≠—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ–ª—É—á–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–º—è –∏ —Ç–µ–ª–µ—Ñ–æ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —á—Ç–æ–±—ã –ø–µ—Ä–µ–¥–∞—Ç—å –∏—Ö –º–µ–Ω–µ–¥–∂–µ—Ä—É.\n\n–ù–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–∞–∫—Ç—ã —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ ‚Äî –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–µ–¥–∞–≤–∞–π –∏—Ö —á–µ—Ä–µ–∑ —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç. \n–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –≤–µ–∂–ª–∏–≤–æ –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Å–æ–æ–±—â–∏, —á—Ç–æ –º–µ–Ω–µ–¥–∂–µ—Ä—ã —Å–∫–æ—Ä–æ —Å–≤—è–∂—É—Ç—Å—è —Å –Ω–∏–º.",
          "humanMessagePrompt": "{input}",
          "promptValues": "",
          "messageHistory": "messageHistoryCode"
        },
        "outputAnchors": [
          {
            "id": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
            "name": "chatPromptTemplate",
            "label": "ChatPromptTemplate",
            "description": "Schema to represent a chat prompt",
            "type": "ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 747,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 266.5353557191726,
        "y": 3195.0731534578217
      }
    },
    {
      "id": "bufferWindowMemory_0",
      "position": {
        "x": 262.56617985543573,
        "y": 1624.8763338217807
      },
      "type": "customNode",
      "data": {
        "id": "bufferWindowMemory_0",
        "label": "Buffer Window Memory",
        "version": 2,
        "name": "bufferWindowMemory",
        "type": "BufferWindowMemory",
        "baseClasses": [
          "BufferWindowMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Uses a window of size k to surface the last k back-and-forth to use as memory",
        "inputParams": [
          {
            "label": "Size",
            "name": "k",
            "type": "number",
            "default": "4",
            "description": "Window of size k to surface the last k back-and-forth to use as memory.",
            "id": "bufferWindowMemory_0-input-k-number",
            "display": true
          },
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "optional": true,
            "additionalParams": true,
            "id": "bufferWindowMemory_0-input-sessionId-string",
            "display": true
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "bufferWindowMemory_0-input-memoryKey-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "k": "20",
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "outputAnchors": [
          {
            "id": "bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory",
            "name": "bufferWindowMemory",
            "label": "BufferWindowMemory",
            "description": "Uses a window of size k to surface the last k back-and-forth to use as memory",
            "type": "BufferWindowMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 337,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 262.56617985543573,
        "y": 1624.8763338217807
      }
    },
    {
      "id": "toolAgent_0",
      "position": {
        "x": 1489.9691454746887,
        "y": 2036.3347995642741
      },
      "type": "customNode",
      "data": {
        "id": "toolAgent_0",
        "label": "Tool Agent",
        "version": 2,
        "name": "toolAgent",
        "type": "AgentExecutor",
        "baseClasses": [
          "AgentExecutor",
          "BaseChain",
          "Runnable"
        ],
        "category": "Agents",
        "description": "Agent that uses Function Calling to pick the tools and args to call",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessage",
            "type": "string",
            "default": "You are a helpful AI assistant.",
            "description": "If Chat Prompt Template is provided, this will be ignored",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-systemMessage-string",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-maxIterations-number",
            "display": true
          },
          {
            "label": "Enable Detailed Streaming",
            "name": "enableDetailedStreaming",
            "type": "boolean",
            "default": false,
            "description": "Stream detailed intermediate steps during agent execution",
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-enableDetailedStreaming-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "toolAgent_0-input-tools-Tool",
            "display": true
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseChatMemory",
            "id": "toolAgent_0-input-memory-BaseChatMemory",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
            "id": "toolAgent_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Chat Prompt Template",
            "name": "chatPromptTemplate",
            "type": "ChatPromptTemplate",
            "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
            "optional": true,
            "id": "toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "toolAgent_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "tools": [
            "{{ChatflowTool_0.data.instance}}"
          ],
          "memory": "{{bufferWindowMemory_0.data.instance}}",
          "model": "{{chatOpenAI_0.data.instance}}",
          "chatPromptTemplate": "{{chatPromptTemplate_0.data.instance}}",
          "systemMessage": "You are a helpful AI assistant.",
          "inputModeration": "",
          "maxIterations": "",
          "enableDetailedStreaming": ""
        },
        "outputAnchors": [
          {
            "id": "toolAgent_0-output-toolAgent-AgentExecutor|BaseChain|Runnable",
            "name": "toolAgent",
            "label": "AgentExecutor",
            "description": "Agent that uses Function Calling to pick the tools and args to call",
            "type": "AgentExecutor | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 491,
      "selected": false,
      "positionAbsolute": {
        "x": 1489.9691454746887,
        "y": 2036.3347995642741
      },
      "dragging": false
    },
    {
      "id": "ChatflowTool_0",
      "position": {
        "x": 1047.5366075254267,
        "y": 1022.0322595390526
      },
      "type": "customNode",
      "data": {
        "id": "ChatflowTool_0",
        "label": "Chatflow Tool",
        "version": 5.1,
        "name": "ChatflowTool",
        "type": "ChatflowTool",
        "baseClasses": [
          "ChatflowTool",
          "Tool"
        ],
        "category": "Tools",
        "description": "Use as a tool to execute another chatflow",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "chatflowApi"
            ],
            "optional": true,
            "id": "ChatflowTool_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Select Chatflow",
            "name": "selectedChatflow",
            "type": "asyncOptions",
            "loadMethod": "listChatflows",
            "id": "ChatflowTool_0-input-selectedChatflow-asyncOptions",
            "display": true
          },
          {
            "label": "Tool Name",
            "name": "name",
            "type": "string",
            "id": "ChatflowTool_0-input-name-string",
            "display": true
          },
          {
            "label": "Tool Description",
            "name": "description",
            "type": "string",
            "description": "Description of what the tool does. This is for LLM to determine when to use this tool.",
            "rows": 3,
            "placeholder": "State of the Union QA - useful for when you need to ask questions about the most recent state of the union address.",
            "id": "ChatflowTool_0-input-description-string",
            "display": true
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "type": "boolean",
            "optional": true,
            "id": "ChatflowTool_0-input-returnDirect-boolean",
            "display": true
          },
          {
            "label": "Override Config",
            "name": "overrideConfig",
            "description": "Override the config passed to the Chatflow.",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "acceptVariable": true,
            "id": "ChatflowTool_0-input-overrideConfig-json",
            "display": true
          },
          {
            "label": "Base URL",
            "name": "baseURL",
            "type": "string",
            "description": "Base URL to Flowise. By default, it is the URL of the incoming request. Useful when you need to execute the Chatflow through an alternative route.",
            "placeholder": "http://localhost:3000",
            "optional": true,
            "additionalParams": true,
            "id": "ChatflowTool_0-input-baseURL-string",
            "display": true
          },
          {
            "label": "Start new session per message",
            "name": "startNewSession",
            "type": "boolean",
            "description": "Whether to continue the session with the Chatflow tool or start a new one with each interaction. Useful for Chatflows with memory if you want to avoid it.",
            "default": false,
            "optional": true,
            "additionalParams": true,
            "id": "ChatflowTool_0-input-startNewSession-boolean",
            "display": true
          },
          {
            "label": "Use Question from Chat",
            "name": "useQuestionFromChat",
            "type": "boolean",
            "description": "Whether to use the question from the chat as input to the chatflow. If turned on, this will override the custom input.",
            "optional": true,
            "additionalParams": true,
            "id": "ChatflowTool_0-input-useQuestionFromChat-boolean",
            "display": true
          },
          {
            "label": "Custom Input",
            "name": "customInput",
            "type": "string",
            "description": "Custom input to be passed to the chatflow. Leave empty to let LLM decides the input.",
            "optional": true,
            "additionalParams": true,
            "show": {
              "useQuestionFromChat": false
            },
            "id": "ChatflowTool_0-input-customInput-string",
            "display": false
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedChatflow": "ff9888cb-7d31-4ae6-b73b-eafee4486e39",
          "name": "process_contacts",
          "description": "–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, —á—Ç–æ–±—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç–∞ ‚Äî –∏–º—è –∏ –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–∞–π–¥–µ–Ω—ã –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n",
          "returnDirect": false,
          "overrideConfig": "",
          "baseURL": "",
          "startNewSession": "",
          "useQuestionFromChat": "",
          "customInput": ""
        },
        "outputAnchors": [
          {
            "id": "ChatflowTool_0-output-ChatflowTool-ChatflowTool|Tool",
            "name": "ChatflowTool",
            "label": "ChatflowTool",
            "description": "Use as a tool to execute another chatflow",
            "type": "ChatflowTool | Tool"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 802,
      "selected": false,
      "positionAbsolute": {
        "x": 1047.5366075254267,
        "y": 1022.0322595390526
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "ChatflowTool_0",
      "sourceHandle": "ChatflowTool_0-output-ChatflowTool-ChatflowTool|Tool",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "ChatflowTool_0-ChatflowTool_0-output-ChatflowTool-ChatflowTool|Tool-toolAgent_0-toolAgent_0-input-tools-Tool"
    },
    {
      "source": "chatPromptTemplate_0",
      "sourceHandle": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate",
      "type": "buttonedge",
      "id": "chatPromptTemplate_0-chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable-toolAgent_0-toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate"
    },
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-toolAgent_0-toolAgent_0-input-model-BaseChatModel"
    },
    {
      "source": "bufferWindowMemory_0",
      "sourceHandle": "bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-memory-BaseChatMemory",
      "type": "buttonedge",
      "id": "bufferWindowMemory_0-bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory-toolAgent_0-toolAgent_0-input-memory-BaseChatMemory"
    }
  ]
}